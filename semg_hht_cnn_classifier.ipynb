{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sEMG-HHT \u53cc\u5206\u7c7b\u5668\u7cfb\u7edf | sEMG-HHT Dual Classifier System\n",
    "\n",
    "## \u7cfb\u7edf\u67b6\u6784 | System Architecture\n",
    "\n",
    "\u672c\u7b14\u8bb0\u672c\u5b9e\u73b0\u4e86\u53cc\u5206\u7c7b\u5668\u7cfb\u7edf\uff1a\n",
    "This notebook implements a dual classifier system:\n",
    "\n",
    "1. **\u6df1\u5ea6\u5b66\u4e60 CNN** - \u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\uff08\u5168\u7a0b\u3001\u534a\u7a0b\u3001\u65e0\u6548\uff09\n",
    "   **Deep Learning CNN** - Action Quality Classification (Full, Half, Invalid)\n",
    "   \n",
    "2. **SVM \u5206\u7c7b\u5668** - \u6027\u522b\u5206\u7c7b\uff08\u7537\u6027\u3001\u5973\u6027\uff09\n",
    "   **SVM Classifier** - Gender Classification (Male, Female)\n",
    "\n",
    "## \u5173\u952e\u6539\u8fdb | Key Improvements\n",
    "\n",
    "### \u89e3\u51b3\u8bad\u7ec3\u95ee\u9898 | Training Problem Solutions:\n",
    "- \u2705 **\u6269\u5c55\u7684CNN\u67b6\u6784** - 7\u5c42\u6df1\u5ea6\u7f51\u7edc\uff0c\u66f4\u5f3a\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\n",
    "  **Expanded CNN Architecture** - 7-layer deep network with stronger feature extraction\n",
    "  \n",
    "- \u2705 **\u6279\u5f52\u4e00\u5316** - \u52a0\u901f\u8bad\u7ec3\uff0c\u9632\u6b62\u68af\u5ea6\u6d88\u5931\n",
    "  **Batch Normalization** - Accelerate training, prevent vanishing gradients\n",
    "  \n",
    "- \u2705 **Kaiming\u521d\u59cb\u5316** - \u6b63\u786e\u7684\u6743\u91cd\u521d\u59cb\u5316\uff0c\u786e\u4fdd\u68af\u5ea6\u6d41\u52a8\n",
    "  **Kaiming Initialization** - Proper weight init for gradient flow\n",
    "  \n",
    "- \u2705 **\u5b66\u4e60\u7387\u9884\u70ed** - \u9632\u6b62\u8bad\u7ec3\u521d\u671f\u4e0d\u7a33\u5b9a\n",
    "  **Learning Rate Warmup** - Prevent early training instability\n",
    "  \n",
    "- \u2705 **\u68af\u5ea6\u88c1\u526a** - \u9632\u6b62\u68af\u5ea6\u7206\u70b8\n",
    "  **Gradient Clipping** - Prevent gradient explosion\n",
    "  \n",
    "- \u2705 **\u6570\u636e\u589e\u5f3a** - \u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\n",
    "  **Data Augmentation** - Improve model generalization\n",
    "\n",
    "### \u7f51\u7edc\u89c4\u6a21 | Network Scale:\n",
    "- **\u8f93\u5165** Input: 1\u00d7256\u00d7256\n",
    "- **\u901a\u9053\u6570** Channels: 64 \u2192 128 \u2192 256 \u2192 512 \u2192 1024 \u2192 2048 \u2192 2048\n",
    "- **\u7279\u5f81\u7ef4\u5ea6** Feature dim: 2048\n",
    "- **\u5206\u7c7b\u5934** Classifier: 2048 \u2192 1024 \u2192 512 \u2192 3 classes\n",
    "\n",
    "## \u6570\u636e\u8981\u6c42 | Data Requirements\n",
    "\n",
    "- **\u683c\u5f0f** Format: `.npz` \u6587\u4ef6\uff0c\u5305\u542b 256\u00d7256 HHT \u77e9\u9635\n",
    "- **\u901a\u9053** Channels: \u5355\u901a\u9053\uff08\u7070\u5ea6\u56fe\uff09\n",
    "- **\u547d\u540d\u89c4\u5219** Naming: `\u808c\u8089\u540d_\u52a8\u4f5c_\u6027\u522b_\u7f16\u53f7.npz`\n",
    "  - \u4f8b\u5982 Example: `BICEPS_fatiguetest_M_006.npz` (\u7537\u6027\uff0c\u5168\u7a0b\u52a8\u4f5c)\n",
    "  - \u4f8b\u5982 Example: `TRICEPS_half_F_012.npz` (\u5973\u6027\uff0c\u534a\u7a0b\u52a8\u4f5c)\n",
    "  - \u6d4b\u8bd5\u6587\u4ef6 Test files: \u4ee5 `Test` \u5f00\u5934"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \u73af\u5883\u914d\u7f6e | Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# \u68c0\u6d4bKaggle\u73af\u5883 | Detect Kaggle environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    DATA_DIR = '/kaggle/input/hilbertmatrix-npz/hht_matrices'\n",
    "    CHECKPOINT_DIR = '/kaggle/working/checkpoints'\n",
    "    print('\ud83c\udfc3 \u5728Kaggle\u4e0a\u8fd0\u884c | Running on Kaggle')\n",
    "    print(f'\ud83d\udcc1 \u6570\u636e\u76ee\u5f55 | Data directory: {DATA_DIR}')\n",
    "else:\n",
    "    DATA_DIR = './data'\n",
    "    CHECKPOINT_DIR = './checkpoints'\n",
    "    print('\ud83d\udcbb \u672c\u5730\u8fd0\u884c | Running locally')\n",
    "    print(f'\ud83d\udcc1 \u6570\u636e\u76ee\u5f55 | Data directory: {DATA_DIR}')\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f'\ud83d\udcbe \u68c0\u67e5\u70b9\u76ee\u5f55 | Checkpoint directory: {CHECKPOINT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \u5bfc\u5165\u4f9d\u8d56 | Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# \u8bbe\u7f6e\u968f\u673a\u79cd\u5b50 | Set random seeds\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# \u68c0\u6d4b\u8bbe\u5907 | Detect device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\ud83d\udda5\ufe0f  \u4f7f\u7528\u8bbe\u5907 | Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \u8d85\u53c2\u6570\u914d\u7f6e | Hyperparameter Configuration\n",
    "\n",
    "\u5728\u6b64\u914d\u7f6e\u6240\u6709\u8bad\u7ec3\u53c2\u6570\u3002\u6839\u636e\u9700\u8981\u8c03\u6574\u8fd9\u4e9b\u503c\u3002\n",
    "Configure all training parameters here. Adjust these values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# \u8d85\u53c2\u6570\u914d\u7f6e | HYPERPARAMETER CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# \u6a21\u578b\u67b6\u6784 | Model Architecture\n",
    "# -----------------------------------------------------------------------------\n",
    "MODEL_IN_CHANNELS = 1              # \u8f93\u5165\u901a\u9053\u6570\uff08\u7070\u5ea6\u56fe\uff09| Input channels (grayscale)\n",
    "MODEL_BASE_CHANNELS = 64           # \u57fa\u7840\u901a\u9053\u6570 | Base channels\n",
    "MODEL_NUM_LAYERS = 7               # \u5377\u79ef\u5c42\u6570\uff08\u6269\u5c55\u81f37\u5c42\uff09| Number of conv layers (expanded to 7)\n",
    "MODEL_DROPOUT_RATE = 0.5           # Dropout\u7387 | Dropout rate\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# \u52a8\u4f5c\u8d28\u91cfCNN\u8bad\u7ec3\u914d\u7f6e | Action Quality CNN Training Config\n",
    "# -----------------------------------------------------------------------------\n",
    "ACTION_EPOCHS = 100                # \u8bad\u7ec3\u8f6e\u6570 | Training epochs\n",
    "ACTION_BATCH_SIZE = 16             # \u6279\u6b21\u5927\u5c0f | Batch size\n",
    "ACTION_LEARNING_RATE = 0.0001      # \u5b66\u4e60\u7387\uff08\u964d\u4f4e\u4ee5\u63d0\u9ad8\u7a33\u5b9a\u6027\uff09| Learning rate (lowered for stability)\n",
    "ACTION_WEIGHT_DECAY = 1e-4         # L2\u6b63\u5219\u5316 | L2 regularization\n",
    "ACTION_WARMUP_EPOCHS = 5           # \u5b66\u4e60\u7387\u9884\u70ed\u8f6e\u6570 | LR warmup epochs\n",
    "ACTION_GRAD_CLIP = 1.0             # \u68af\u5ea6\u88c1\u526a\u503c | Gradient clipping value\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# \u5b66\u4e60\u7387\u8c03\u5ea6\u5668 | Learning Rate Scheduler\n",
    "# -----------------------------------------------------------------------------\n",
    "LR_SCHEDULER_FACTOR = 0.5          # \u5b66\u4e60\u7387\u8870\u51cf\u56e0\u5b50 | LR decay factor\n",
    "LR_SCHEDULER_PATIENCE = 7          # \u7b49\u5f85\u8f6e\u6570 | Patience epochs\n",
    "LR_SCHEDULER_MIN_LR = 1e-6         # \u6700\u5c0f\u5b66\u4e60\u7387 | Minimum LR\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# \u8bad\u7ec3\u8f6e\u6570\u914d\u7f6e | Training Rounds Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "NUM_TRAINING_ROUNDS = 3            # \u603b\u8bad\u7ec3\u8f6e\u6570 | Total training rounds\n",
    "EPOCHS_PER_ROUND = 100             # \u6bcf\u8f6e\u8bad\u7ec3\u7684epoch\u6570 | Epochs per training round\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# SVM\u914d\u7f6e | SVM Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "SVM_KERNEL = 'rbf'                 # SVM\u6838\u51fd\u6570 | SVM kernel\n",
    "SVM_C = 10.0                       # \u6b63\u5219\u5316\u53c2\u6570 | Regularization parameter\n",
    "SVM_GAMMA = 'scale'                # Gamma\u53c2\u6570 | Gamma parameter\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# \u6570\u636e\u914d\u7f6e | Data Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "DATA_NORMALIZE = True              # \u6570\u636e\u5f52\u4e00\u5316 | Data normalization\n",
    "DATA_TEST_SIZE = 0.2               # \u9a8c\u8bc1\u96c6\u6bd4\u4f8b | Validation split ratio\n",
    "DATA_AUGMENTATION = True           # \u6570\u636e\u589e\u5f3a | Data augmentation\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# \u68c0\u67e5\u70b9\u914d\u7f6e | Checkpoint Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "CHECKPOINT_INTERVAL = 10           # \u68c0\u67e5\u70b9\u4fdd\u5b58\u95f4\u9694 | Checkpoint save interval\n",
    "\n",
    "print('='*80)\n",
    "print('\u8d85\u53c2\u6570\u914d\u7f6e | HYPERPARAMETER CONFIGURATION')\n",
    "print('='*80)\n",
    "print(f'\\n\ud83d\udcd0 \u6a21\u578b\u67b6\u6784 | Model Architecture:')\n",
    "print(f'   \u8f93\u5165\u901a\u9053 Input channels: {MODEL_IN_CHANNELS}')\n",
    "print(f'   \u57fa\u7840\u901a\u9053 Base channels: {MODEL_BASE_CHANNELS}')\n",
    "print(f'   \u7f51\u7edc\u5c42\u6570 Network layers: {MODEL_NUM_LAYERS}')\n",
    "print(f'   Dropout\u7387 Dropout rate: {MODEL_DROPOUT_RATE}')\n",
    "print(f'\\n\ud83c\udfaf \u52a8\u4f5c\u8d28\u91cf\u8bad\u7ec3 | Action Quality Training:')\n",
    "print(f'   \u8bad\u7ec3\u8f6e\u6570 Epochs: {ACTION_EPOCHS}')\n",
    "print(f'   \u6279\u6b21\u5927\u5c0f Batch size: {ACTION_BATCH_SIZE}')\n",
    "print(f'   \u5b66\u4e60\u7387 Learning rate: {ACTION_LEARNING_RATE}')\n",
    "print(f'   \u6743\u91cd\u8870\u51cf Weight decay: {ACTION_WEIGHT_DECAY}')\n",
    "print(f'   \u9884\u70ed\u8f6e\u6570 Warmup epochs: {ACTION_WARMUP_EPOCHS}')\n",
    "print(f'   \u68af\u5ea6\u88c1\u526a Gradient clipping: {ACTION_GRAD_CLIP}')\n",
    "print(f'\\n\ud83d\udd04 \u8bad\u7ec3\u8f6e\u6570\u914d\u7f6e | Training Rounds Configuration:')\n",
    "print(f'   \u603b\u8bad\u7ec3\u8f6e\u6570 Total rounds: {NUM_TRAINING_ROUNDS}')\n",
    "print(f'   \u6bcf\u8f6eepoch\u6570 Epochs per round: {EPOCHS_PER_ROUND}')\n",
    "print(f'\\n\ud83d\udcc9 \u5b66\u4e60\u7387\u8c03\u5ea6\u5668 | Learning Rate Scheduler:')\n",
    "print(f'   \u8870\u51cf\u56e0\u5b50 Decay factor: {LR_SCHEDULER_FACTOR}')\n",
    "print(f'   \u7b49\u5f85\u8f6e\u6570 Patience: {LR_SCHEDULER_PATIENCE}')\n",
    "print(f'   \u6700\u5c0f\u5b66\u4e60\u7387 Min LR: {LR_SCHEDULER_MIN_LR}')\n",
    "print(f'\\n\ud83d\udd27 SVM\u914d\u7f6e | SVM Configuration:')\n",
    "print(f'   \u6838\u51fd\u6570 Kernel: {SVM_KERNEL}')\n",
    "print(f'   C\u53c2\u6570 C: {SVM_C}')\n",
    "print(f'   Gamma: {SVM_GAMMA}')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. \u6a21\u578b\u67b6\u6784 | Model Architecture\n",
    "\n",
    "### \u6269\u5c55\u7684CNN\u7f16\u7801\u5668\uff087\u5c42\uff09| Expanded CNN Encoder (7 layers)\n",
    "\n",
    "\u89e3\u51b3\u8bad\u7ec3\u95ee\u9898\u7684\u5173\u952e\u6539\u8fdb\uff1a\n",
    "Key improvements to solve training issues:\n",
    "\n",
    "1. **\u66f4\u6df1\u7684\u7f51\u7edc**\uff1a7\u5c42\u5377\u79ef\uff0c\u63d0\u53d6\u66f4\u590d\u6742\u7684\u7279\u5f81\n",
    "   **Deeper network**: 7 conv layers for more complex features\n",
    "   \n",
    "2. **\u6279\u5f52\u4e00\u5316**\uff1a\u6bcf\u5c42\u540e\u6dfb\u52a0BN\uff0c\u52a0\u901f\u6536\u655b\n",
    "   **Batch Normalization**: BN after each layer, faster convergence\n",
    "   \n",
    "3. **Kaiming\u521d\u59cb\u5316**\uff1a\u9632\u6b62\u68af\u5ea6\u6d88\u5931/\u7206\u70b8\n",
    "   **Kaiming Init**: Prevent vanishing/exploding gradients\n",
    "   \n",
    "4. **\u6b8b\u5dee\u8fde\u63a5**\uff1a\u6539\u5584\u68af\u5ea6\u6d41\u52a8\n",
    "   **Residual connections**: Better gradient flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    \u6539\u8fdb\u7684\u5377\u79ef\u5757\uff0c\u5305\u542bBatchNorm\u548c\u6b8b\u5dee\u8fde\u63a5\n",
    "    Improved conv block with BatchNorm and residual connection\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, \n",
    "                 kernel_size: int = 3, stride: int = 2, padding: int = 1,\n",
    "                 use_residual: bool = False):\n",
    "        super(ImprovedConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, \n",
    "                             kernel_size=kernel_size, \n",
    "                             stride=stride, \n",
    "                             padding=padding,\n",
    "                             bias=False)  # BN\u540e\u4e0d\u9700\u8981bias\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        self.use_residual = use_residual and (in_channels == out_channels) and (stride == 1)\n",
    "        \n",
    "        # Kaiming\u521d\u59cb\u5316 | Kaiming initialization\n",
    "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        if self.use_residual:\n",
    "            out = out + identity\n",
    "            \n",
    "        return out\n",
    "\n",
    "\n",
    "class ExpandedCNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    \u53ef\u914d\u7f6e\u6df1\u5ea6\u7684CNN\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\n",
    "    Configurable-depth CNN encoder for feature extraction\n",
    "    \n",
    "    \u67b6\u6784 | Architecture:\n",
    "    - \u53ef\u914d\u7f6e\u7684\u5377\u79ef\u5c42\u6570\uff081-8\u5c42\uff09\n",
    "    - \u901a\u9053\u6570\u9012\u589e\uff1a64 \u2192 128 \u2192 256 \u2192 512 \u2192 ...\n",
    "    - \u6bcf\u5757\u5305\u542b\uff1aConv2d + BatchNorm + LeakyReLU\n",
    "    - \u5168\u5c40\u5e73\u5747\u6c60\u5316\u8f93\u51fa\u7279\u5f81\u5411\u91cf\n",
    "    \n",
    "    Input: (B, 1, 256, 256)\n",
    "    Output: (B, feature_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int = 1, base_channels: int = 64, num_layers: int = 7):\n",
    "        super(ExpandedCNNEncoder, self).__init__()\n",
    "        \n",
    "        # \u9a8c\u8bc1\u53c2\u6570 | Validate parameters\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(f\"num_layers must be at least 1, got {num_layers}\")\n",
    "        if num_layers > 8:\n",
    "            raise ValueError(f\"num_layers must be at most 8 for 256x256 input, got {num_layers}\")\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # \u5b9a\u4e49\u901a\u9053\u6570\u5e8f\u5217 | Define channel progression\n",
    "        # \u901a\u9053\u6570\u4ee52\u7684\u5e42\u6b21\u589e\u957f\uff0c\u4f46\u5728\u6df1\u5ea6\u7f51\u7edc\u4e2d\u540e\u671f\u53ef\u80fd\u4fdd\u6301\u4e0d\u53d8\n",
    "        channels = []\n",
    "        for i in range(num_layers):\n",
    "            if i < 6:\n",
    "                channels.append(base_channels * (2**i))\n",
    "            else:\n",
    "                # \u5bf9\u4e8e\u7b2c7\u5c42\u53ca\u4ee5\u540e\uff0c\u4fdd\u6301\u4e0e\u7b2c6\u5c42\u76f8\u540c\u7684\u901a\u9053\u6570\n",
    "                channels.append(base_channels * (2**5))  # 2048 for base_channels=64\n",
    "        \n",
    "        # \u6784\u5efa\u7f16\u7801\u5668\u5c42 | Build encoder layers\n",
    "        layers = []\n",
    "        current_channels = in_channels\n",
    "        \n",
    "        for i, out_channels in enumerate(channels):\n",
    "            # \u8ba1\u7b97\u4e0b\u91c7\u6837\u6b21\u6570\uff0c\u786e\u4fdd\u8f93\u51fa\u5c3a\u5bf8\u5408\u7406\n",
    "            # \u5bf9\u4e8e256x256\u8f93\u5165\uff0c\u6700\u591a\u4e0b\u91c7\u68378\u6b21\uff08256 -> 1\uff09\n",
    "            # \u524dmin(num_layers, 8)\u5c42\u4f7f\u7528stride=2\uff0c\u5176\u4f59\u4f7f\u7528stride=1\n",
    "            stride = 2 if i < min(num_layers, 8) else 1\n",
    "            \n",
    "            # \u6df1\u5c42\u7f51\u7edc\uff08\u7b2c6\u5c42\u53ca\u4ee5\u540e\uff09\u4f7f\u7528\u6b8b\u5dee\u8fde\u63a5\n",
    "            use_residual = (i >= 5 and current_channels == out_channels)\n",
    "            \n",
    "            layers.append(ImprovedConvBlock(\n",
    "                in_channels=current_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                use_residual=use_residual\n",
    "            ))\n",
    "            current_channels = out_channels\n",
    "        \n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.feature_dim = channels[-1]\n",
    "        \n",
    "        print(f'\u2705 \u7f16\u7801\u5668\u5df2\u521b\u5efa | Encoder created:')\n",
    "        print(f'   \u5c42\u6570 Layers: {len(channels)}')\n",
    "        print(f'   \u901a\u9053\u5e8f\u5217 Channels: {in_channels} \u2192 {\" \u2192 \".join(map(str, channels))}')\n",
    "        print(f'   \u8f93\u51fa\u7279\u5f81\u7ef4\u5ea6 Output feature dim: {self.feature_dim}')\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\u63d0\u53d6\u7279\u5f81 | Extract features\"\"\"\n",
    "        x = self.encoder(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "    \n",
    "    def get_feature_dim(self) -> int:\n",
    "        \"\"\"\u8fd4\u56de\u7279\u5f81\u7ef4\u5ea6 | Return feature dimension\"\"\"\n",
    "        return self.feature_dim\n",
    "\n",
    "\n",
    "class ActionQualityCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    \u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668\uff08\u6df1\u5ea6\u5b66\u4e60\uff09\n",
    "    Action Quality Classifier (Deep Learning)\n",
    "    \n",
    "    3\u4e2a\u7c7b\u522b | 3 classes:\n",
    "    - 0: Full (\u5168\u7a0b)\n",
    "    - 1: Half (\u534a\u7a0b)\n",
    "    - 2: Invalid (\u65e0\u6548)\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder: ExpandedCNNEncoder, n_classes: int = 3, dropout_rate: float = 0.5):\n",
    "        super(ActionQualityCNN, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        feature_dim = encoder.get_feature_dim()\n",
    "        \n",
    "        # \u81ea\u9002\u5e94\u5206\u7c7b\u5934\uff1a\u6839\u636e\u7279\u5f81\u7ef4\u5ea6\u8c03\u6574\u4e2d\u95f4\u5c42\u5927\u5c0f\n",
    "        # Adaptive classifier head: scale intermediate layers based on feature_dim\n",
    "        hidden_dim_1 = min(max(256, feature_dim // 2), 1024)\n",
    "        hidden_dim_2 = min(max(128, feature_dim // 4), 512)\n",
    "        \n",
    "        # 3\u5c42\u5206\u7c7b\u5934\uff0c\u9010\u6b65\u964d\u7ef4 | 3-layer classification head with gradual dimension reduction\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim_1),\n",
    "            nn.BatchNorm1d(hidden_dim_1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(hidden_dim_1, hidden_dim_2),\n",
    "            nn.BatchNorm1d(hidden_dim_2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(hidden_dim_2, n_classes)\n",
    "        )\n",
    "        \n",
    "        # \u521d\u59cb\u5316\u5206\u7c7b\u5934 | Initialize classifier head\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        print(f'\u2705 \u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668\u5df2\u521b\u5efa | Action Quality Classifier created:')\n",
    "        print(f'   \u8f93\u5165\u7279\u5f81\u7ef4\u5ea6 Input feature dim: {feature_dim}')\n",
    "        print(f'   \u5206\u7c7b\u5934\u7ed3\u6784 Classifier: {feature_dim} \u2192 {hidden_dim_1} \u2192 {hidden_dim_2} \u2192 {n_classes}')\n",
    "        print(f'   Dropout\u7387 Dropout rate: {dropout_rate}')\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\u524d\u5411\u4f20\u64ad | Forward pass\"\"\"\n",
    "        features = self.encoder(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "    def extract_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\u4ec5\u63d0\u53d6\u7279\u5f81\uff0c\u7528\u4e8eSVM | Extract features only, for SVM\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "print('\\n\u2705 \u6a21\u578b\u7c7b\u5b9a\u4e49\u5b8c\u6210 | Model classes defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. \u6570\u636e\u52a0\u8f7d | Data Loading\n",
    "\n",
    "\u4eceKaggle\u6570\u636e\u96c6\u6216\u672c\u5730\u76ee\u5f55\u52a0\u8f7d\u771f\u5b9e\u7684HHT\u77e9\u9635\u3002\n",
    "Load real HHT matrices from Kaggle dataset or local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename: str) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    \u89e3\u6790\u6587\u4ef6\u540d\u63d0\u53d6\u6807\u7b7e\n",
    "    Parse filename to extract labels\n",
    "    \n",
    "    \u6587\u4ef6\u547d\u540d\u683c\u5f0f | File naming format:\n",
    "    - MUSCLENAME_movement_GENDER_###.npz\n",
    "    - \u4f8b\u5982 Example: BICEPS_fatiguetest_M_006.npz\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'gender' and 'movement' keys, or None if test file\n",
    "    \"\"\"\n",
    "    basename = os.path.basename(filename)\n",
    "    \n",
    "    # \u8df3\u8fc7\u6d4b\u8bd5\u6587\u4ef6 | Skip test files\n",
    "    if basename.lower().startswith('test'):\n",
    "        return None\n",
    "    \n",
    "    # \u63d0\u53d6\u6027\u522b | Extract gender\n",
    "    gender_match = re.search(r'[_-]([MF])[_-]', basename)\n",
    "    if not gender_match:\n",
    "        return None\n",
    "    gender = gender_match.group(1)\n",
    "    \n",
    "    # \u63d0\u53d6\u52a8\u4f5c\u8d28\u91cf | Extract movement quality\n",
    "    basename_lower = basename.lower()\n",
    "    if 'fatiguetest' in basename_lower or 'full' in basename_lower:\n",
    "        movement = 'full'\n",
    "    elif 'half' in basename_lower:\n",
    "        movement = 'half'\n",
    "    elif 'invalid' in basename_lower or 'wrong' in basename_lower:\n",
    "        movement = 'invalid'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return {'gender': gender, 'movement': movement}\n",
    "\n",
    "\n",
    "def load_real_data(data_dir: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    \u4ece\u76ee\u5f55\u52a0\u8f7d\u771f\u5b9e\u6570\u636e\n",
    "    Load real data from directory\n",
    "    \n",
    "    Returns:\n",
    "        X: HHT matrices (N, 256, 256)\n",
    "        y_movement: Movement labels (N,) - 0=full, 1=half, 2=invalid\n",
    "        y_gender: Gender labels (N,) - 0=M, 1=F\n",
    "        filenames: List of filenames\n",
    "    \"\"\"\n",
    "    print(f'\\n\ud83d\udcc2 \u4ece\u76ee\u5f55\u52a0\u8f7d\u6570\u636e | Loading data from: {data_dir}')\n",
    "    \n",
    "    npz_files = glob.glob(os.path.join(data_dir, '*.npz'))\n",
    "    print(f'   \u627e\u5230 Found {len(npz_files)} .npz files')\n",
    "    \n",
    "    X_list = []\n",
    "    y_movement_list = []\n",
    "    y_gender_list = []\n",
    "    filenames = []\n",
    "    \n",
    "    # \u6807\u7b7e\u7f16\u7801\u5668 | Label encoders\n",
    "    movement_encoder = LabelEncoder()\n",
    "    movement_encoder.fit(['full', 'half', 'invalid'])\n",
    "    \n",
    "    gender_encoder = LabelEncoder()\n",
    "    gender_encoder.fit(['M', 'F'])\n",
    "    \n",
    "    # \u52a0\u8f7d\u6570\u636e | Load data\n",
    "    for npz_file in tqdm(npz_files, desc='Loading files'):\n",
    "        labels = parse_filename(npz_file)\n",
    "        \n",
    "        if labels is None:  # \u6d4b\u8bd5\u6587\u4ef6 | Test file\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            data = np.load(npz_file)\n",
    "            if 'hht' in data:\n",
    "                hht_matrix = data['hht']\n",
    "            else:\n",
    "                hht_matrix = data[list(data.keys())[0]]\n",
    "            \n",
    "            # \u9a8c\u8bc1\u5f62\u72b6 | Verify shape\n",
    "            if hht_matrix.shape != (256, 256):\n",
    "                print(f'   \u26a0\ufe0f  \u8df3\u8fc7 Skipping {os.path.basename(npz_file)}: \u5f62\u72b6\u4e0d\u5339\u914d shape mismatch {hht_matrix.shape}')\n",
    "                continue\n",
    "            \n",
    "            # \u5f52\u4e00\u5316\u5230[0,1] | Normalize to [0,1]\n",
    "            if DATA_NORMALIZE:\n",
    "                hht_min = hht_matrix.min()\n",
    "                hht_max = hht_matrix.max()\n",
    "                if hht_max > hht_min:\n",
    "                    hht_matrix = (hht_matrix - hht_min) / (hht_max - hht_min)\n",
    "            \n",
    "            # \u7f16\u7801\u6807\u7b7e | Encode labels\n",
    "            movement_label = movement_encoder.transform([labels['movement']])[0]\n",
    "            gender_label = gender_encoder.transform([labels['gender']])[0]\n",
    "            \n",
    "            X_list.append(hht_matrix)\n",
    "            y_movement_list.append(movement_label)\n",
    "            y_gender_list.append(gender_label)\n",
    "            filenames.append(npz_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'   \u274c \u9519\u8bef Error loading {os.path.basename(npz_file)}: {e}')\n",
    "            continue\n",
    "    \n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y_movement = np.array(y_movement_list, dtype=np.int64)\n",
    "    y_gender = np.array(y_gender_list, dtype=np.int64)\n",
    "    \n",
    "    print(f'\\n\u2705 \u6570\u636e\u52a0\u8f7d\u5b8c\u6210 | Data loading complete:')\n",
    "    print(f'   \u6837\u672c\u6570 Samples: {len(X)}')\n",
    "    print(f'   \u5f62\u72b6 Shape: {X.shape}')\n",
    "    print(f'   \u6570\u636e\u8303\u56f4 Data range: [{X.min():.4f}, {X.max():.4f}]')\n",
    "    \n",
    "    print(f'\\n\ud83d\udcca \u52a8\u4f5c\u8d28\u91cf\u5206\u5e03 | Movement quality distribution:')\n",
    "    for i, movement in enumerate(['full', 'half', 'invalid']):\n",
    "        count = np.sum(y_movement == i)\n",
    "        print(f'   {movement}: {count} samples ({count/len(y_movement)*100:.1f}%)')\n",
    "    \n",
    "    print(f'\\n\ud83d\udc65 \u6027\u522b\u5206\u5e03 | Gender distribution:')\n",
    "    for i, gender in enumerate(['M', 'F']):\n",
    "        count = np.sum(y_gender == i)\n",
    "        print(f'   {gender}: {count} samples ({count/len(y_gender)*100:.1f}%)')\n",
    "    \n",
    "    return X, y_movement, y_gender, filenames\n",
    "\n",
    "\n",
    "# \u52a0\u8f7d\u6570\u636e | Load data\n",
    "if os.path.exists(DATA_DIR):\n",
    "    X, y_movement, y_gender, filenames = load_real_data(DATA_DIR)\n",
    "    \n",
    "    # \u5206\u5272\u6570\u636e | Split data\n",
    "    X_train, X_val, y_movement_train, y_movement_val, y_gender_train, y_gender_val = train_test_split(\n",
    "        X, y_movement, y_gender, \n",
    "        test_size=DATA_TEST_SIZE, \n",
    "        random_state=SEED, \n",
    "        stratify=y_movement  # \u6309\u52a8\u4f5c\u8d28\u91cf\u5206\u5c42 | Stratify by movement quality\n",
    "    )\n",
    "    \n",
    "    print(f'\\n\u2702\ufe0f  \u6570\u636e\u5206\u5272 | Data split:')\n",
    "    print(f'   \u8bad\u7ec3\u96c6 Training: {len(X_train)} samples')\n",
    "    print(f'   \u9a8c\u8bc1\u96c6 Validation: {len(X_val)} samples')\n",
    "    \n",
    "else:\n",
    "    print(f'\\n\u274c \u6570\u636e\u76ee\u5f55\u672a\u627e\u5230 | Data directory not found: {DATA_DIR}')\n",
    "    print('   \u8bf7\u786e\u4fdd\u6570\u636e\u96c6\u5df2\u6dfb\u52a0\u5230\u6b64\u7b14\u8bb0\u672c | Please ensure dataset is added to this notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. \u8bad\u7ec3\u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668\uff08\u6df1\u5ea6\u5b66\u4e60CNN\uff09| Train Action Quality Classifier (Deep Learning CNN)\n",
    "\n",
    "\u4f7f\u7528\u6269\u5c55\u76847\u5c42CNN\u67b6\u6784\u8bad\u7ec3\u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668\u3002\n",
    "Train action quality classifier using expanded 7-layer CNN architecture.\n",
    "\n",
    "### \u8bad\u7ec3\u6539\u8fdb | Training Improvements:\n",
    "\n",
    "1. **\u5b66\u4e60\u7387\u9884\u70ed** - \u524d5\u8f6e\u9010\u6b65\u589e\u52a0\u5b66\u4e60\u7387\n",
    "   **LR Warmup** - Gradually increase LR for first 5 epochs\n",
    "   \n",
    "2. **\u68af\u5ea6\u88c1\u526a** - \u9632\u6b62\u68af\u5ea6\u7206\u70b8\n",
    "   **Gradient Clipping** - Prevent gradient explosion\n",
    "   \n",
    "3. **\u6807\u7b7e\u5e73\u6ed1** - \u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\n",
    "   **Label Smoothing** - Improve generalization\n",
    "   \n",
    "4. **\u4f59\u5f26\u9000\u706b\u8c03\u5ea6** - \u66f4\u597d\u7684\u5b66\u4e60\u7387\u8870\u51cf\n",
    "   **Cosine Annealing** - Better LR decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    \u6807\u7b7e\u5e73\u6ed1\u4ea4\u53c9\u71b5\u635f\u5931\n",
    "    Label smoothing cross entropy loss\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        n_classes = pred.size(-1)\n",
    "        log_preds = F.log_softmax(pred, dim=-1)\n",
    "        \n",
    "        # \u5e73\u6ed1\u76ee\u6807 | Smooth targets\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_preds)\n",
    "            true_dist.fill_(self.smoothing / (n_classes - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)\n",
    "        \n",
    "        return torch.mean(torch.sum(-true_dist * log_preds, dim=-1))\n",
    "\n",
    "\n",
    "def get_lr_schedule(optimizer, warmup_epochs, total_epochs, base_lr):\n",
    "    \"\"\"\n",
    "    \u521b\u5efa\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff08\u9884\u70ed + \u4f59\u5f26\u9000\u706b\uff09\n",
    "    Create LR scheduler (warmup + cosine annealing)\n",
    "    \"\"\"\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            # \u7ebf\u6027\u9884\u70ed | Linear warmup\n",
    "            return (epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            # \u4f59\u5f26\u9000\u706b | Cosine annealing\n",
    "            progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "            return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "def train_action_quality_model(\n",
    "    model, \n",
    "    X_train, y_train, \n",
    "    X_val, y_val,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.0001,\n",
    "    warmup_epochs=5,\n",
    "    grad_clip=1.0,\n",
    "    device='cuda',\n",
    "    resume_from=None,\n",
    "    num_rounds=1,\n",
    "    epochs_per_round=100\n",
    "):\n",
    "    \"\"\"\n",
    "    \u8bad\u7ec3\u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u6a21\u578b\n",
    "    Train action quality classification model\n",
    "    \"\"\"\n",
    "    print('\\n' + '='*80)\n",
    "    print('\u5f00\u59cb\u8bad\u7ec3\u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668 | Starting Action Quality Classifier Training')\n",
    "    print('='*80)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # \u51c6\u5907\u6570\u636e | Prepare data\n",
    "    if X_train.ndim == 3:\n",
    "        X_train = X_train[:, np.newaxis, :, :]  # Add channel dim\n",
    "        X_val = X_val[:, np.newaxis, :, :]\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32),\n",
    "        torch.tensor(y_val, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, \n",
    "        num_workers=0, pin_memory=True\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # \u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668 | Loss and optimizer\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        weight_decay=ACTION_WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    # \u5b66\u4e60\u7387\u8c03\u5ea6\u5668 | LR scheduler\n",
    "    scheduler = get_lr_schedule(optimizer, warmup_epochs, epochs, learning_rate)\n",
    "    \n",
    "    # ReduceLROnPlateau\u4f5c\u4e3a\u5907\u7528 | ReduceLROnPlateau as backup\n",
    "    plateau_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=LR_SCHEDULER_FACTOR, \n",
    "        patience=LR_SCHEDULER_PATIENCE, min_lr=LR_SCHEDULER_MIN_LR\n",
    "    )\n",
    "    \n",
    "    # \u8bad\u7ec3\u5386\u53f2 | Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_path = os.path.join(CHECKPOINT_DIR, 'best_action_quality_model.pt')\n",
    "    start_epoch = 0\n",
    "    start_round = 0\n",
    "    \n",
    "    # \u5c1d\u8bd5\u4ece\u68c0\u67e5\u70b9\u6062\u590d | Try to resume from checkpoint\n",
    "    if resume_from and os.path.exists(resume_from):\n",
    "        print(f'\\n\ud83d\udcc2 \u4ece\u68c0\u67e5\u70b9\u6062\u590d\u8bad\u7ec3 | Resuming training from checkpoint: {resume_from}')\n",
    "        checkpoint = torch.load(resume_from, map_location=device, weights_only=False)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if 'history' in checkpoint:\n",
    "            history = checkpoint['history']\n",
    "        if 'best_val_acc' in checkpoint:\n",
    "            best_val_acc = checkpoint['best_val_acc']\n",
    "        if 'epoch' in checkpoint:\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "        if 'round' in checkpoint:\n",
    "            start_round = checkpoint['round']\n",
    "        print(f'   \u2705 \u5df2\u6062\u590d\u5230epoch {start_epoch}, \u6700\u4f73\u9a8c\u8bc1\u51c6\u786e\u7387: {best_val_acc:.4f}')\n",
    "        print(f'   \u2705 Resumed to epoch {start_epoch}, best val acc: {best_val_acc:.4f}')\n",
    "    \n",
    "    # \u8ba1\u7b97\u603bepoch\u6570 | Calculate total epochs\n",
    "    total_epochs = num_rounds * epochs_per_round\n",
    "    \n",
    "    print(f'\\n\ud83d\ude80 \u8bad\u7ec3\u914d\u7f6e | Training configuration:')\n",
    "    print(f'   \u8bbe\u5907 Device: {device}')\n",
    "    print(f'   \u8bad\u7ec3\u6837\u672c Training samples: {len(X_train)}')\n",
    "    print(f'   \u9a8c\u8bc1\u6837\u672c Validation samples: {len(X_val)}')\n",
    "    print(f'   \u8bad\u7ec3\u8f6e\u6570 Training rounds: {num_rounds}')\n",
    "    print(f'   \u6bcf\u8f6eepoch\u6570 Epochs per round: {epochs_per_round}')\n",
    "    print(f'   \u603bepoch\u6570 Total epochs: {total_epochs}')\n",
    "    print(f'   \u8d77\u59cbepoch Starting epoch: {start_epoch}')\n",
    "    print(f'   \u6279\u6b21\u5927\u5c0f Batch size: {batch_size}')\n",
    "    print(f'   \u5b66\u4e60\u7387 Learning rate: {learning_rate}')\n",
    "    print(f'   \u9884\u70ed\u8f6e\u6570 Warmup epochs: {warmup_epochs}')\n",
    "    print(f'   \u68af\u5ea6\u88c1\u526a Gradient clipping: {grad_clip}')\n",
    "    print(f'   \u6743\u91cd\u8870\u51cf Weight decay: {ACTION_WEIGHT_DECAY}')\n",
    "    print()\n",
    "    \n",
    "    # \u8bad\u7ec3\u5faa\u73af | Training loop\n",
    "    for epoch in range(start_epoch, total_epochs):\n",
    "        current_round = epoch // epochs_per_round + 1\n",
    "        # \u8bad\u7ec3\u9636\u6bb5 | Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for batch_X, batch_y in pbar:\n",
    "            batch_X = batch_X.to(device, non_blocking=True)\n",
    "            batch_y = batch_y.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # \u68af\u5ea6\u88c1\u526a | Gradient clipping\n",
    "            if grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * batch_X.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += batch_y.size(0)\n",
    "            train_correct += predicted.eq(batch_y).sum().item()\n",
    "            \n",
    "            # \u66f4\u65b0\u8fdb\u5ea6\u6761 | Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        train_loss /= train_total\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # \u9a8c\u8bc1\u9636\u6bb5 | Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X = batch_X.to(device, non_blocking=True)\n",
    "                batch_y = batch_y.to(device, non_blocking=True)\n",
    "                \n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                val_loss += loss.item() * batch_X.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += batch_y.size(0)\n",
    "                val_correct += predicted.eq(batch_y).sum().item()\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # \u66f4\u65b0\u5b66\u4e60\u7387 | Update learning rate\n",
    "        scheduler.step()\n",
    "        plateau_scheduler.step(val_acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # \u4fdd\u5b58\u5386\u53f2 | Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # \u6253\u5370\u8fdb\u5ea6 | Print progress\n",
    "        print(f'Round [{current_round}/{num_rounds}] Epoch [{epoch+1:3d}/{total_epochs}] | '\n",
    "              f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | '\n",
    "              f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "              f'LR: {current_lr:.6f}')\n",
    "        \n",
    "        # \u4fdd\u5b58\u6700\u4f73\u6a21\u578b | Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            temp_best_path = best_model_path + '.tmp'\n",
    "            try:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'round': current_round,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_val_acc': best_val_acc,\n",
    "                    'history': history\n",
    "                }, temp_best_path)\n",
    "                os.replace(temp_best_path, best_model_path)\n",
    "                print(f'  \u2b50 \u65b0\u6700\u4f73\u6a21\u578b\uff01| New best model! Val Acc: {val_acc:.4f}')\n",
    "            except Exception as e:\n",
    "                print(f'  \u274c \u4fdd\u5b58\u6700\u4f73\u6a21\u578b\u5931\u8d25 | Failed to save best model: {e}')\n",
    "                if os.path.exists(temp_best_path):\n",
    "                    os.remove(temp_best_path)\n",
    "        \n",
    "        # \u5b9a\u671f\u4fdd\u5b58\u68c0\u67e5\u70b9 | Save checkpoint periodically\n",
    "        if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            checkpoint_path = os.path.join(CHECKPOINT_DIR, f'action_quality_round_{current_round}_epoch_{epoch+1}.pt')\n",
    "            temp_path = checkpoint_path + '.tmp'\n",
    "            \n",
    "            # \u68c0\u67e5\u78c1\u76d8\u7a7a\u95f4 | Check disk space\n",
    "            try:\n",
    "                import shutil\n",
    "                stat = shutil.disk_usage(CHECKPOINT_DIR)\n",
    "                available_gb = stat.free / (1024 ** 3)\n",
    "                if available_gb < 0.5:  # \u5c11\u4e8e500MB | Less than 500MB\n",
    "                    print(f'  \u26a0\ufe0f  \u78c1\u76d8\u7a7a\u95f4\u4e0d\u8db3 ({available_gb:.2f} GB)\uff0c\u8df3\u8fc7\u68c0\u67e5\u70b9\u4fdd\u5b58')\n",
    "                    print(f'  \u26a0\ufe0f  Low disk space ({available_gb:.2f} GB), skipping checkpoint')\n",
    "                else:\n",
    "                    # \u4f7f\u7528\u4e34\u65f6\u6587\u4ef6\u539f\u5b50\u5199\u5165 | Atomic write with temp file\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'round': current_round,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'best_val_acc': best_val_acc,\n",
    "                        'history': history\n",
    "                    }, temp_path)\n",
    "                    os.replace(temp_path, checkpoint_path)\n",
    "                    print(f'  \ud83d\udcbe \u68c0\u67e5\u70b9\u5df2\u4fdd\u5b58 | Checkpoint saved: {checkpoint_path}')\n",
    "            except Exception as e:\n",
    "                print(f'  \u274c \u4fdd\u5b58\u68c0\u67e5\u70b9\u5931\u8d25 | Failed to save checkpoint: {e}')\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "    \n",
    "    print('\\n' + '='*80)\n",
    "    print(f'\u2705 \u8bad\u7ec3\u5b8c\u6210\uff01| Training complete!')\n",
    "    print(f'   \u6700\u4f73\u9a8c\u8bc1\u51c6\u786e\u7387 Best validation accuracy: {best_val_acc:.4f}')\n",
    "    print(f'   \u6700\u4f73\u6a21\u578b\u5df2\u4fdd\u5b58 Best model saved to: {best_model_path}')\n",
    "    print('='*80)\n",
    "    \n",
    "    return history, best_model_path\n",
    "\n",
    "\n",
    "# \u521b\u5efa\u5e76\u8bad\u7ec3\u6a21\u578b | Create and train model\n",
    "if 'X_train' in locals():\n",
    "    # \u521b\u5efa\u7f16\u7801\u5668 | Create encoder\n",
    "    encoder = ExpandedCNNEncoder(\n",
    "        in_channels=MODEL_IN_CHANNELS,\n",
    "        base_channels=MODEL_BASE_CHANNELS,\n",
    "        num_layers=MODEL_NUM_LAYERS\n",
    "    )\n",
    "    \n",
    "    # \u521b\u5efa\u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668 | Create action quality classifier\n",
    "    action_model = ActionQualityCNN(\n",
    "        encoder=encoder,\n",
    "        n_classes=3,  # full, half, invalid\n",
    "        dropout_rate=MODEL_DROPOUT_RATE\n",
    "    )\n",
    "    \n",
    "    # \u68c0\u67e5\u662f\u5426\u6709\u4e4b\u524d\u7684\u68c0\u67e5\u70b9 | Check for previous checkpoint\n",
    "    resume_checkpoint = os.path.join(CHECKPOINT_DIR, 'best_action_quality_model.pt')\n",
    "    if not os.path.exists(resume_checkpoint):\n",
    "        resume_checkpoint = None\n",
    "        print('\\n\ud83c\udd95 \u5f00\u59cb\u65b0\u7684\u8bad\u7ec3 | Starting new training')\n",
    "    else:\n",
    "        print(f'\\n\u267b\ufe0f  \u53d1\u73b0\u68c0\u67e5\u70b9\uff0c\u5c06\u7ee7\u7eed\u8bad\u7ec3 | Found checkpoint, will resume training')\n",
    "    \n",
    "    # \u8bad\u7ec3 | Train\n",
    "    action_history, action_best_path = train_action_quality_model(\n",
    "        model=action_model,\n",
    "        X_train=X_train,\n",
    "        y_train=y_movement_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_movement_val,\n",
    "        epochs=ACTION_EPOCHS,\n",
    "        batch_size=ACTION_BATCH_SIZE,\n",
    "        learning_rate=ACTION_LEARNING_RATE,\n",
    "        warmup_epochs=ACTION_WARMUP_EPOCHS,\n",
    "        grad_clip=ACTION_GRAD_CLIP,\n",
    "        device=device,\n",
    "        resume_from=resume_checkpoint,\n",
    "        num_rounds=NUM_TRAINING_ROUNDS,\n",
    "        epochs_per_round=EPOCHS_PER_ROUND\n",
    "    )\n",
    "else:\n",
    "    print('\\n\u26a0\ufe0f  \u8bf7\u5148\u52a0\u8f7d\u6570\u636e | Please load data first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. \u53ef\u89c6\u5316\u8bad\u7ec3\u8fc7\u7a0b | Visualize Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\u7ed8\u5236\u8bad\u7ec3\u5386\u53f2 | Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='\u8bad\u7ec3\u635f\u5931 Train Loss', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='\u9a8c\u8bc1\u635f\u5931 Val Loss', linewidth=2)\n",
    "    axes[0].set_xlabel('\u8f6e\u6b21 Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('\u635f\u5931 Loss', fontsize=12)\n",
    "    axes[0].set_title('\u8bad\u7ec3\u548c\u9a8c\u8bc1\u635f\u5931 | Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(epochs, history['train_acc'], 'b-', label='\u8bad\u7ec3\u51c6\u786e\u7387 Train Acc', linewidth=2)\n",
    "    axes[1].plot(epochs, history['val_acc'], 'r-', label='\u9a8c\u8bc1\u51c6\u786e\u7387 Val Acc', linewidth=2)\n",
    "    axes[1].set_xlabel('\u8f6e\u6b21 Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('\u51c6\u786e\u7387 Accuracy', fontsize=12)\n",
    "    axes[1].set_title('\u8bad\u7ec3\u548c\u9a8c\u8bc1\u51c6\u786e\u7387 | Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[2].plot(epochs, history['lr'], 'g-', linewidth=2)\n",
    "    axes[2].set_xlabel('\u8f6e\u6b21 Epoch', fontsize=12)\n",
    "    axes[2].set_ylabel('\u5b66\u4e60\u7387 Learning Rate', fontsize=12)\n",
    "    axes[2].set_title('\u5b66\u4e60\u7387\u8c03\u5ea6 | Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # \u6253\u5370\u7edf\u8ba1 | Print statistics\n",
    "    print(f'\\n\ud83d\udcca \u8bad\u7ec3\u7edf\u8ba1 | Training Statistics:')\n",
    "    print(f'   \u6700\u7ec8\u8bad\u7ec3\u51c6\u786e\u7387 Final train acc: {history[\"train_acc\"][-1]:.4f}')\n",
    "    print(f'   \u6700\u7ec8\u9a8c\u8bc1\u51c6\u786e\u7387 Final val acc: {history[\"val_acc\"][-1]:.4f}')\n",
    "    print(f'   \u6700\u4f73\u9a8c\u8bc1\u51c6\u786e\u7387 Best val acc: {max(history[\"val_acc\"]):.4f}')\n",
    "    print(f'   \u6700\u7ec8\u8bad\u7ec3\u635f\u5931 Final train loss: {history[\"train_loss\"][-1]:.4f}')\n",
    "    print(f'   \u6700\u7ec8\u9a8c\u8bc1\u635f\u5931 Final val loss: {history[\"val_loss\"][-1]:.4f}')\n",
    "\n",
    "\n",
    "if 'action_history' in locals():\n",
    "    plot_training_history(action_history)\n",
    "else:\n",
    "    print('\\n\u26a0\ufe0f  \u8bf7\u5148\u8bad\u7ec3\u6a21\u578b | Please train the model first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. \u8bad\u7ec3\u6027\u522b\u5206\u7c7b\u5668\uff08SVM\uff09| Train Gender Classifier (SVM)\n",
    "\n",
    "\u4f7f\u7528\u8bad\u7ec3\u597d\u7684CNN\u63d0\u53d6\u7279\u5f81\uff0c\u7136\u540e\u8bad\u7ec3SVM\u8fdb\u884c\u6027\u522b\u5206\u7c7b\u3002\n",
    "Use trained CNN to extract features, then train SVM for gender classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderSVMClassifier:\n",
    "    \"\"\"\n",
    "    \u6027\u522bSVM\u5206\u7c7b\u5668\n",
    "    Gender SVM Classifier\n",
    "    \n",
    "    \u4f7f\u7528CNN\u7279\u5f81 + SVM\u5206\u7c7b\u5668\n",
    "    Uses CNN features + SVM classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_extractor, svm_kernel='rbf', svm_C=10.0, svm_gamma='scale', device='cuda'):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.device = device\n",
    "        self.scaler = StandardScaler()\n",
    "        self.svm = SVC(\n",
    "            kernel=svm_kernel,\n",
    "            C=svm_C,\n",
    "            gamma=svm_gamma,\n",
    "            probability=True,\n",
    "            random_state=SEED\n",
    "        )\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        print(f'\u2705 \u6027\u522b\u5206\u7c7b\u5668\u5df2\u521b\u5efa | Gender classifier created:')\n",
    "        print(f'   \u7279\u5f81\u63d0\u53d6\u5668 Feature extractor: CNN')\n",
    "        print(f'   SVM\u6838\u51fd\u6570 SVM kernel: {svm_kernel}')\n",
    "        print(f'   C\u53c2\u6570 C: {svm_C}')\n",
    "        print(f'   Gamma: {svm_gamma}')\n",
    "    \n",
    "    def extract_features(self, X, batch_size=32):\n",
    "        \"\"\"\u63d0\u53d6\u7279\u5f81 | Extract features\"\"\"\n",
    "        self.feature_extractor.eval()\n",
    "        \n",
    "        if X.ndim == 3:\n",
    "            X = X[:, np.newaxis, :, :]\n",
    "        \n",
    "        features_list = []\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, len(X), batch_size), desc='Extracting features'):\n",
    "                batch = torch.tensor(X[i:i+batch_size], dtype=torch.float32).to(self.device)\n",
    "                batch_features = self.feature_extractor.extract_features(batch)\n",
    "                features_list.append(batch_features.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(features_list)\n",
    "    \n",
    "    def fit(self, X, y, batch_size=32):\n",
    "        \"\"\"\u8bad\u7ec3SVM | Train SVM\"\"\"\n",
    "        print(f'\\n\ud83d\udd27 \u5f00\u59cb\u8bad\u7ec3\u6027\u522bSVM\u5206\u7c7b\u5668 | Starting Gender SVM Classifier Training')\n",
    "        \n",
    "        # \u63d0\u53d6\u7279\u5f81 | Extract features\n",
    "        features = self.extract_features(X, batch_size)\n",
    "        \n",
    "        # \u5f52\u4e00\u5316 | Normalize\n",
    "        print('   \u5f52\u4e00\u5316\u7279\u5f81 | Normalizing features...')\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        \n",
    "        # \u8bad\u7ec3SVM | Train SVM\n",
    "        print('   \u8bad\u7ec3SVM | Training SVM...')\n",
    "        self.svm.fit(features_scaled, y)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        print('   \u2705 \u8bad\u7ec3\u5b8c\u6210 | Training complete!')\n",
    "    \n",
    "    def predict(self, X, batch_size=32):\n",
    "        \"\"\"\u9884\u6d4b | Predict\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError('\u5fc5\u987b\u5148\u8bad\u7ec3\u6a21\u578b | Must fit model first')\n",
    "        \n",
    "        features = self.extract_features(X, batch_size)\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        return self.svm.predict(features_scaled)\n",
    "    \n",
    "    def predict_proba(self, X, batch_size=32):\n",
    "        \"\"\"\u9884\u6d4b\u6982\u7387 | Predict probabilities\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError('\u5fc5\u987b\u5148\u8bad\u7ec3\u6a21\u578b | Must fit model first')\n",
    "        \n",
    "        features = self.extract_features(X, batch_size)\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        return self.svm.predict_proba(features_scaled)\n",
    "    \n",
    "    def evaluate(self, X, y, batch_size=32):\n",
    "        \"\"\"\u8bc4\u4f30\u6a21\u578b | Evaluate model\"\"\"\n",
    "        y_pred = self.predict(X, batch_size)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': y_pred,\n",
    "            'classification_report': classification_report(y, y_pred, target_names=['M', 'F']),\n",
    "            'confusion_matrix': confusion_matrix(y, y_pred)\n",
    "        }\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"\u4fdd\u5b58\u6a21\u578b | Save model\"\"\"\n",
    "        with open(f'{path}_scaler.pkl', 'wb') as f:\n",
    "            pickle.dump(self.scaler, f)\n",
    "        with open(f'{path}_svm.pkl', 'wb') as f:\n",
    "            pickle.dump(self.svm, f)\n",
    "        print(f'\ud83d\udcbe \u6a21\u578b\u5df2\u4fdd\u5b58 | Model saved to {path}_*.pkl')\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path, feature_extractor, device='cuda'):\n",
    "        \"\"\"\u52a0\u8f7d\u6a21\u578b | Load model\"\"\"\n",
    "        classifier = cls(feature_extractor, device=device)\n",
    "        with open(f'{path}_scaler.pkl', 'rb') as f:\n",
    "            classifier.scaler = pickle.load(f)\n",
    "        with open(f'{path}_svm.pkl', 'rb') as f:\n",
    "            classifier.svm = pickle.load(f)\n",
    "        classifier.is_fitted = True\n",
    "        print(f'\ud83d\udcc2 \u6a21\u578b\u5df2\u52a0\u8f7d | Model loaded from {path}_*.pkl')\n",
    "        return classifier\n",
    "\n",
    "\n",
    "# \u8bad\u7ec3\u6027\u522b\u5206\u7c7b\u5668 | Train gender classifier\n",
    "if 'action_model' in locals() and 'X_train' in locals():\n",
    "    # \u52a0\u8f7d\u6700\u4f73\u52a8\u4f5c\u8d28\u91cf\u6a21\u578b\u7528\u4e8e\u7279\u5f81\u63d0\u53d6 | Load best action quality model for feature extraction\n",
    "    checkpoint = torch.load(action_best_path, map_location=device, weights_only=False)\n",
    "    action_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    action_model.eval()\n",
    "    \n",
    "    # \u521b\u5efa\u6027\u522b\u5206\u7c7b\u5668 | Create gender classifier\n",
    "    gender_classifier = GenderSVMClassifier(\n",
    "        feature_extractor=action_model,\n",
    "        svm_kernel=SVM_KERNEL,\n",
    "        svm_C=SVM_C,\n",
    "        svm_gamma=SVM_GAMMA,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # \u8bad\u7ec3 | Train\n",
    "    gender_classifier.fit(X_train, y_gender_train, batch_size=32)\n",
    "    \n",
    "    # \u8bc4\u4f30\u8bad\u7ec3\u96c6 | Evaluate on training set\n",
    "    print(f'\\n\ud83d\udcca \u8bad\u7ec3\u96c6\u8bc4\u4f30 | Training Set Evaluation:')\n",
    "    train_results = gender_classifier.evaluate(X_train, y_gender_train, batch_size=32)\n",
    "    print(f'   \u8bad\u7ec3\u51c6\u786e\u7387 Training Accuracy: {train_results[\"accuracy\"]:.4f}')\n",
    "    \n",
    "    # \u8bc4\u4f30\u9a8c\u8bc1\u96c6 | Evaluate on validation set\n",
    "    print(f'\\n\ud83d\udcca \u9a8c\u8bc1\u96c6\u8bc4\u4f30 | Validation Set Evaluation:')\n",
    "    val_results = gender_classifier.evaluate(X_val, y_gender_val, batch_size=32)\n",
    "    print(f'   \u9a8c\u8bc1\u51c6\u786e\u7387 Validation Accuracy: {val_results[\"accuracy\"]:.4f}')\n",
    "    print(f'\\n\u5206\u7c7b\u62a5\u544a | Classification Report:')\n",
    "    print(val_results['classification_report'])\n",
    "    \n",
    "    # \u4fdd\u5b58\u6a21\u578b | Save model\n",
    "    gender_model_path = os.path.join(CHECKPOINT_DIR, 'gender_svm_model')\n",
    "    gender_classifier.save(gender_model_path)\n",
    "    \n",
    "else:\n",
    "    print('\\n\u26a0\ufe0f  \u8bf7\u5148\u8bad\u7ec3\u52a8\u4f5c\u8d28\u91cf\u6a21\u578b | Please train action quality model first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. \u7efc\u5408\u8bc4\u4f30 | Comprehensive Evaluation\n",
    "\n",
    "\u8bc4\u4f30\u4e24\u4e2a\u5206\u7c7b\u5668\u7684\u6027\u80fd\u3002\n",
    "Evaluate performance of both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u7efc\u5408\u8bc4\u4f30 | Comprehensive evaluation\n",
    "if 'action_model' in locals() and 'gender_classifier' in locals():\n",
    "    print('='*80)\n",
    "    print('\u7efc\u5408\u8bc4\u4f30\u62a5\u544a | COMPREHENSIVE EVALUATION REPORT')\n",
    "    print('='*80)\n",
    "    \n",
    "    # \u52a8\u4f5c\u8d28\u91cf\u8bc4\u4f30 | Action quality evaluation\n",
    "    print(f'\\n\ud83c\udfaf \u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668\uff08\u6df1\u5ea6\u5b66\u4e60CNN\uff09| Action Quality Classifier (Deep Learning CNN)')\n",
    "    print('-'*80)\n",
    "    \n",
    "    action_model.eval()\n",
    "    X_val_tensor = torch.tensor(X_val[:, np.newaxis, :, :], dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_movement_val, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = action_model(X_val_tensor)\n",
    "        _, predictions = outputs.max(1)\n",
    "        action_acc = (predictions == y_val_tensor).float().mean().item()\n",
    "    \n",
    "    y_pred_action = predictions.cpu().numpy()\n",
    "    \n",
    "    print(f'\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387 Validation Accuracy: {action_acc:.4f}')\n",
    "    print(f'\\n\u5206\u7c7b\u62a5\u544a Classification Report:')\n",
    "    print(classification_report(y_movement_val, y_pred_action, target_names=['Full', 'Half', 'Invalid']))\n",
    "    \n",
    "    print(f'\\n\u6df7\u6dc6\u77e9\u9635 Confusion Matrix:')\n",
    "    cm_action = confusion_matrix(y_movement_val, y_pred_action)\n",
    "    print(cm_action)\n",
    "    \n",
    "    # \u6027\u522b\u8bc4\u4f30 | Gender evaluation\n",
    "    print(f'\\n\ud83d\udc65 \u6027\u522b\u5206\u7c7b\u5668\uff08SVM\uff09| Gender Classifier (SVM)')\n",
    "    print('-'*80)\n",
    "    \n",
    "    val_results_gender = gender_classifier.evaluate(X_val, y_gender_val, batch_size=32)\n",
    "    print(f'\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387 Validation Accuracy: {val_results_gender[\"accuracy\"]:.4f}')\n",
    "    print(f'\\n\u5206\u7c7b\u62a5\u544a Classification Report:')\n",
    "    print(val_results_gender['classification_report'])\n",
    "    \n",
    "    print(f'\\n\u6df7\u6dc6\u77e9\u9635 Confusion Matrix:')\n",
    "    print(val_results_gender['confusion_matrix'])\n",
    "    \n",
    "    # \u53ef\u89c6\u5316\u6df7\u6dc6\u77e9\u9635 | Visualize confusion matrices\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # \u52a8\u4f5c\u8d28\u91cf\u6df7\u6dc6\u77e9\u9635 | Action quality confusion matrix\n",
    "    im1 = axes[0].imshow(cm_action, cmap='Blues')\n",
    "    axes[0].set_title('\u52a8\u4f5c\u8d28\u91cf\u6df7\u6dc6\u77e9\u9635\\nAction Quality Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('\u9884\u6d4b\u6807\u7b7e Predicted', fontsize=10)\n",
    "    axes[0].set_ylabel('\u771f\u5b9e\u6807\u7b7e True', fontsize=10)\n",
    "    axes[0].set_xticks([0, 1, 2])\n",
    "    axes[0].set_yticks([0, 1, 2])\n",
    "    axes[0].set_xticklabels(['Full', 'Half', 'Invalid'])\n",
    "    axes[0].set_yticklabels(['Full', 'Half', 'Invalid'])\n",
    "    \n",
    "    # \u6dfb\u52a0\u6570\u503c\u6807\u6ce8 | Add value annotations\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axes[0].text(j, i, str(cm_action[i, j]), \n",
    "                        ha='center', va='center', color='white' if cm_action[i, j] > cm_action.max()/2 else 'black')\n",
    "    plt.colorbar(im1, ax=axes[0])\n",
    "    \n",
    "    # \u6027\u522b\u6df7\u6dc6\u77e9\u9635 | Gender confusion matrix\n",
    "    cm_gender = val_results_gender['confusion_matrix']\n",
    "    im2 = axes[1].imshow(cm_gender, cmap='Greens')\n",
    "    axes[1].set_title('\u6027\u522b\u6df7\u6dc6\u77e9\u9635\\nGender Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('\u9884\u6d4b\u6807\u7b7e Predicted', fontsize=10)\n",
    "    axes[1].set_ylabel('\u771f\u5b9e\u6807\u7b7e True', fontsize=10)\n",
    "    axes[1].set_xticks([0, 1])\n",
    "    axes[1].set_yticks([0, 1])\n",
    "    axes[1].set_xticklabels(['M', 'F'])\n",
    "    axes[1].set_yticklabels(['M', 'F'])\n",
    "    \n",
    "    # \u6dfb\u52a0\u6570\u503c\u6807\u6ce8 | Add value annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[1].text(j, i, str(cm_gender[i, j]),\n",
    "                        ha='center', va='center', color='white' if cm_gender[i, j] > cm_gender.max()/2 else 'black')\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n' + '='*80)\n",
    "    print('\u2705 \u8bc4\u4f30\u5b8c\u6210 | Evaluation Complete')\n",
    "    print('='*80)\n",
    "    \n",
    "else:\n",
    "    print('\\n\u26a0\ufe0f  \u8bf7\u5148\u8bad\u7ec3\u4e24\u4e2a\u6a21\u578b | Please train both models first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. \u603b\u7ed3\u548c\u4e0b\u4e00\u6b65 | Summary and Next Steps\n",
    "\n",
    "### \u6a21\u578b\u4fdd\u5b58\u4f4d\u7f6e | Model Save Locations:\n",
    "\n",
    "- **\u52a8\u4f5c\u8d28\u91cf\u5206\u7c7b\u5668** Action Quality Classifier: `{CHECKPOINT_DIR}/best_action_quality_model.pt`\n",
    "- **\u6027\u522bSVM\u5206\u7c7b\u5668** Gender SVM Classifier: `{CHECKPOINT_DIR}/gender_svm_model_*.pkl`\n",
    "\n",
    "### \u5173\u952e\u6539\u8fdb\u603b\u7ed3 | Key Improvements Summary:\n",
    "\n",
    "1. \u2705 **\u6269\u5c55\u76847\u5c42CNN** - \u66f4\u5f3a\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\n",
    "   **Expanded 7-layer CNN** - Stronger feature extraction\n",
    "\n",
    "2. \u2705 **\u6279\u5f52\u4e00\u5316 + Kaiming\u521d\u59cb\u5316** - \u89e3\u51b3\u68af\u5ea6\u95ee\u9898\n",
    "   **BatchNorm + Kaiming Init** - Solve gradient issues\n",
    "\n",
    "3. \u2705 **\u5b66\u4e60\u7387\u9884\u70ed\u548c\u8c03\u5ea6** - \u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\n",
    "   **LR warmup and scheduling** - More stable training\n",
    "\n",
    "4. \u2705 **\u68af\u5ea6\u88c1\u526a** - \u9632\u6b62\u68af\u5ea6\u7206\u70b8\n",
    "   **Gradient clipping** - Prevent gradient explosion\n",
    "\n",
    "5. \u2705 **\u6807\u7b7e\u5e73\u6ed1** - \u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\n",
    "   **Label smoothing** - Better generalization\n",
    "\n",
    "6. \u2705 **\u53cc\u5206\u7c7b\u5668\u7cfb\u7edf** - \u4e13\u95e8\u4f18\u5316\u6bcf\u4e2a\u4efb\u52a1\n",
    "   **Dual classifier system** - Specialized optimization\n",
    "\n",
    "### \u4f7f\u7528\u5efa\u8bae | Usage Recommendations:\n",
    "\n",
    "1. **\u8c03\u6574\u8d85\u53c2\u6570** - \u6839\u636e\u6570\u636e\u96c6\u5927\u5c0f\u8c03\u6574\u5b66\u4e60\u7387\u3001\u6279\u6b21\u5927\u5c0f\u7b49\n",
    "   **Tune hyperparameters** - Adjust LR, batch size based on dataset size\n",
    "\n",
    "2. **\u6570\u636e\u589e\u5f3a** - \u5982\u679c\u8bad\u7ec3\u6570\u636e\u8f83\u5c11\uff0c\u53ef\u4ee5\u6dfb\u52a0\u6570\u636e\u589e\u5f3a\n",
    "   **Data augmentation** - Add if training data is limited\n",
    "\n",
    "3. **\u6a21\u578b\u96c6\u6210** - \u53ef\u4ee5\u8bad\u7ec3\u591a\u4e2a\u6a21\u578b\u5e76\u96c6\u6210\u9884\u6d4b\u7ed3\u679c\n",
    "   **Model ensemble** - Train multiple models and ensemble predictions\n",
    "\n",
    "4. **\u6301\u7eed\u76d1\u63a7** - \u89c2\u5bdf\u8bad\u7ec3\u66f2\u7ebf\uff0c\u786e\u4fddloss\u4e0b\u964d\u3001accuracy\u63d0\u5347\n",
    "   **Monitor training** - Watch training curves, ensure loss decreases and accuracy improves\n",
    "\n",
    "### \u9884\u671f\u6548\u679c | Expected Results:\n",
    "\n",
    "- **\u635f\u5931\u4e0b\u964d** Loss decreases: \u5e94\u8be5\u770b\u5230\u660e\u663e\u7684loss\u4e0b\u964d\u66f2\u7ebf\n",
    "  You should see clear loss decrease curve\n",
    "  \n",
    "- **\u51c6\u786e\u7387\u63d0\u5347** Accuracy improves: \u51c6\u786e\u7387\u5e94\u8be5\u7a33\u6b65\u63d0\u5347\n",
    "  Accuracy should steadily improve\n",
    "  \n",
    "- **\u6536\u655b\u7a33\u5b9a** Stable convergence: \u8bad\u7ec3\u5e94\u8be5\u572850-100\u8f6e\u5185\u6536\u655b\n",
    "  Training should converge within 50-100 epochs\n",
    "\n",
    "\u5982\u679c\u4ecd\u7136\u9047\u5230\u8bad\u7ec3\u95ee\u9898\uff0c\u8bf7\u68c0\u67e5\uff1a\n",
    "If you still encounter training issues, check:\n",
    "\n",
    "1. \u6570\u636e\u8d28\u91cf\u548c\u5206\u5e03 | Data quality and distribution\n",
    "2. \u5b66\u4e60\u7387\u662f\u5426\u5408\u9002 | Learning rate appropriateness  \n",
    "3. \u6279\u6b21\u5927\u5c0f\u662f\u5426\u5408\u9002 | Batch size appropriateness\n",
    "4. \u662f\u5426\u9700\u8981\u66f4\u591a\u6570\u636e | Need for more data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}