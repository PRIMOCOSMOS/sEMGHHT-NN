# sEMG-HHT CNN Classifier | sEMG-HHT CNN åˆ†ç±»å™¨

[English](#english) | [ä¸­æ–‡](#chinese)

---

## <a name="english"></a>English Version

A Convolutional Neural Network (CNN) based classifier for surface electromyography (sEMG) signals using Hilbert-Huang Transform (HHT) representation. This project is designed for multi-class classification tasks such as movement quality assessment and gender classification.

### ğŸ¯ Overview

This project implements a deep learning pipeline that:
1. Takes 256Ã—256 HHT matrices as input (derived from sEMG signals)
2. Extracts features using a 3-layer CNN encoder
3. Performs multi-class classification using SVM or end-to-end neural network

### ğŸ—ï¸ Model Architecture

**CNN Encoder Structure:**
- **3 Convolutional Layers**, each containing:
  - Conv2D (kernel=3, stride=2, padding=1)
  - Instance Normalization (maintains data distribution per sample)
  - LeakyReLU activation (slope=0.2)
- **Global Average Pooling** at the end
- Output: 256-dimensional feature vector

**Classifier Options:**
1. **CNN-SVM (Recommended)**: CNN extracts features â†’ SVM classifies (supports 6-class classification)
2. **End-to-End**: Fully trainable neural network with FC layers

### ğŸ“Š Classification Task

**6-Class Multi-Dimensional Classification:**
- **Gender Dimension**: Male (M) / Female (F)
- **Movement Quality Dimension**: 
  - Full (å®Œæ•´åŠ¨ä½œ): Complete movement range
  - Half (åŠç¨‹åŠ¨ä½œ): Partial movement range  
  - Invalid (æ— æ•ˆåŠ¨ä½œ): Incorrect or failed movement

**Class Mapping:**
| Class ID | Label | Gender | Movement |
|----------|-------|--------|----------|
| 0 | M_full | Male | Full |
| 1 | M_half | Male | Half |
| 2 | M_invalid | Male | Invalid |
| 3 | F_full | Female | Full |
| 4 | F_half | Female | Half |
| 5 | F_invalid | Female | Invalid |

### ğŸš€ Quick Start

#### Option 1: Kaggle Notebook (Easiest)

1. Upload `semg_hht_cnn_classifier.ipynb` to Kaggle
2. Add the **HILBERTMATRIX_NPZ** dataset to your notebook
3. Enable GPU accelerator (Settings â†’ Accelerator â†’ GPU)
4. Run all cells

The notebook automatically detects Kaggle environment and loads data from `/kaggle/input/hilbertmatrix-npz/hht_matrices/`

#### Option 2: Command-Line Training (For Local/Server)

```bash
# Install dependencies
pip install -r requirements.txt

# Train with your data
python train.py --data_dir ./data --checkpoint_dir ./checkpoints

# Resume from checkpoint
python train.py --data_dir ./data --checkpoint_dir ./checkpoints --resume

# Run inference
python inference.py --checkpoint ./checkpoints/final --input ./new_data/
```

See [TRAINING_GUIDE.md](TRAINING_GUIDE.md) for detailed instructions.

### ğŸ“ Data Format

**File Naming Convention:**
```
MUSCLENAME_movement_GENDER_###.npz
```

Examples:
- `BICEPS_fatiguetest_M_006.npz` â†’ Male, Full movement
- `TRICEPS_half_F_012.npz` â†’ Female, Half movement
- `FOREARM_invalid_M_003.npz` â†’ Male, Invalid movement
- `Test1_1_015.npz` â†’ Unlabeled test file (starts with "Test")

**File Content:**
Each `.npz` file contains a 256Ã—256 HHT matrix stored with key `'hht'`.

### ğŸ”§ Module Functions

**1. `train.py` - Production Training Script**
- Loads .npz files from directory
- Parses filenames to extract gender and movement labels
- Trains CNN encoder to extract features
- Trains SVM classifier on extracted features
- Saves checkpoints (encoder, scaler, SVM, metadata)
- Evaluates on validation set
- Runs inference on test files (files starting with "Test")

**2. `inference.py` - Inference Script**
- Loads trained model from checkpoint
- Processes single file or batch of files
- Outputs predictions with confidence scores
- Saves results to JSON

**3. `generate_sample_data.py` - Data Generator**
- Creates synthetic 256Ã—256 HHT matrices for testing
- Generates proper filename formats
- Useful for testing the pipeline

**4. Jupyter Notebook `semg_hht_cnn_classifier.ipynb`**
- Interactive exploration and visualization
- Integrated with Kaggle datasets
- Step-by-step training workflow
- Suitable for experimentation

### ğŸ“ˆ Training Process

1. **Data Loading**: Loads all .npz files, filters test files (starting with "Test")
2. **Feature Extraction**: CNN encoder processes 256Ã—256 matrices â†’ 256-dim vectors
3. **Normalization**: StandardScaler normalizes features
4. **SVM Training**: RBF kernel SVM trains on normalized features
5. **Validation**: Computes accuracy, precision, recall, F1-score
6. **Test Inference**: Predicts labels for test files
7. **Checkpoint Saving**: Saves complete model state

---

## <a name="chinese"></a>ä¸­æ–‡ç‰ˆæœ¬

åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„è¡¨é¢è‚Œç”µä¿¡å·ï¼ˆsEMGï¼‰åˆ†ç±»å™¨ï¼Œä½¿ç”¨å¸Œå°”ä¼¯ç‰¹-é»„å˜æ¢ï¼ˆHHTï¼‰è¡¨ç¤ºã€‚è¯¥é¡¹ç›®è®¾è®¡ç”¨äºåŠ¨ä½œè´¨é‡è¯„ä¼°å’Œæ€§åˆ«åˆ†ç±»ç­‰å¤šç±»åˆ†ç±»ä»»åŠ¡ã€‚

### ğŸ¯ æ¦‚è¿°

è¯¥é¡¹ç›®å®ç°äº†ä¸€ä¸ªæ·±åº¦å­¦ä¹ æµç¨‹ï¼š
1. è¾“å…¥ 256Ã—256 çš„ HHT çŸ©é˜µï¼ˆä» sEMG ä¿¡å·å¯¼å‡ºï¼‰
2. ä½¿ç”¨ 3 å±‚ CNN ç¼–ç å™¨æå–ç‰¹å¾
3. ä½¿ç”¨ SVM æˆ–ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œè¿›è¡Œå¤šç±»åˆ†ç±»

### ğŸ—ï¸ æ¨¡å‹æ¶æ„

**CNN ç¼–ç å™¨ç»“æ„ï¼š**
- **3 ä¸ªå·ç§¯å±‚**ï¼Œæ¯å±‚åŒ…å«ï¼š
  - Conv2Dï¼ˆkernel=3, stride=2, padding=1ï¼‰
  - å®ä¾‹å½’ä¸€åŒ–ï¼ˆInstance Normalizationï¼Œä¿æŒæ¯ä¸ªæ ·æœ¬çš„æ•°æ®åˆ†å¸ƒï¼‰
  - LeakyReLU æ¿€æ´»å‡½æ•°ï¼ˆslope=0.2ï¼‰
- æœ«å°¾ä½¿ç”¨**å…¨å±€å¹³å‡æ± åŒ–**
- è¾“å‡ºï¼š256 ç»´ç‰¹å¾å‘é‡

**åˆ†ç±»å™¨é€‰é¡¹ï¼š**
1. **CNN-SVMï¼ˆæ¨èï¼‰**ï¼šCNN æå–ç‰¹å¾ â†’ SVM åˆ†ç±»ï¼ˆæ”¯æŒ 6 ç±»åˆ†ç±»ï¼‰
2. **ç«¯åˆ°ç«¯æ¨¡å‹**ï¼šå…¨è¿æ¥å±‚çš„å®Œå…¨å¯è®­ç»ƒç¥ç»ç½‘ç»œ

### ğŸ“Š åˆ†ç±»ä»»åŠ¡

**6 ç±»å¤šç»´åˆ†ç±»ï¼š**
- **æ€§åˆ«ç»´åº¦**ï¼šç”·æ€§ (M) / å¥³æ€§ (F)
- **åŠ¨ä½œè´¨é‡ç»´åº¦**ï¼š
  - Fullï¼ˆå®Œæ•´åŠ¨ä½œï¼‰ï¼šå®Œæ•´çš„è¿åŠ¨èŒƒå›´
  - Halfï¼ˆåŠç¨‹åŠ¨ä½œï¼‰ï¼šéƒ¨åˆ†è¿åŠ¨èŒƒå›´
  - Invalidï¼ˆæ— æ•ˆåŠ¨ä½œï¼‰ï¼šé”™è¯¯æˆ–å¤±è´¥çš„åŠ¨ä½œ

**ç±»åˆ«æ˜ å°„ï¼š**
| ç±»åˆ« ID | æ ‡ç­¾ | æ€§åˆ« | åŠ¨ä½œ |
|---------|------|------|------|
| 0 | M_full | ç”·æ€§ | å®Œæ•´ |
| 1 | M_half | ç”·æ€§ | åŠç¨‹ |
| 2 | M_invalid | ç”·æ€§ | æ— æ•ˆ |
| 3 | F_full | å¥³æ€§ | å®Œæ•´ |
| 4 | F_half | å¥³æ€§ | åŠç¨‹ |
| 5 | F_invalid | å¥³æ€§ | æ— æ•ˆ |

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### æ–¹å¼ 1ï¼šKaggle ç¬”è®°æœ¬ï¼ˆæœ€ç®€å•ï¼‰

1. å°† `semg_hht_cnn_classifier.ipynb` ä¸Šä¼ åˆ° Kaggle
2. æ·»åŠ  **HILBERTMATRIX_NPZ** æ•°æ®é›†åˆ°ç¬”è®°æœ¬
3. å¯ç”¨ GPU åŠ é€Ÿå™¨ï¼ˆè®¾ç½® â†’ åŠ é€Ÿå™¨ â†’ GPUï¼‰
4. è¿è¡Œæ‰€æœ‰å•å…ƒæ ¼

ç¬”è®°æœ¬ä¼šè‡ªåŠ¨æ£€æµ‹ Kaggle ç¯å¢ƒå¹¶ä» `/kaggle/input/hilbertmatrix-npz/hht_matrices/` åŠ è½½æ•°æ®ã€‚

#### æ–¹å¼ 2ï¼šå‘½ä»¤è¡Œè®­ç»ƒï¼ˆæœ¬åœ°/æœåŠ¡å™¨ï¼‰

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ä½¿ç”¨æ‚¨çš„æ•°æ®è®­ç»ƒ
python train.py --data_dir ./data --checkpoint_dir ./checkpoints

# ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
python train.py --data_dir ./data --checkpoint_dir ./checkpoints --resume

# è¿è¡Œæ¨ç†
python inference.py --checkpoint ./checkpoints/final --input ./new_data/
```

è¯¦ç»†è¯´æ˜è¯·å‚è§ [TRAINING_GUIDE.md](TRAINING_GUIDE.md)ã€‚

### ğŸ“ æ•°æ®æ ¼å¼

**æ–‡ä»¶å‘½åè§„èŒƒï¼š**
```
è‚Œè‚‰åç§°_åŠ¨ä½œç±»å‹_æ€§åˆ«_ç¼–å·.npz
```

ç¤ºä¾‹ï¼š
- `BICEPS_fatiguetest_M_006.npz` â†’ ç”·æ€§ï¼Œå®Œæ•´åŠ¨ä½œ
- `TRICEPS_half_F_012.npz` â†’ å¥³æ€§ï¼ŒåŠç¨‹åŠ¨ä½œ
- `FOREARM_invalid_M_003.npz` â†’ ç”·æ€§ï¼Œæ— æ•ˆåŠ¨ä½œ
- `Test1_1_015.npz` â†’ æœªæ ‡æ³¨æµ‹è¯•æ–‡ä»¶ï¼ˆä»¥ "Test" å¼€å¤´ï¼‰

**æ–‡ä»¶å†…å®¹ï¼š**
æ¯ä¸ª `.npz` æ–‡ä»¶åŒ…å«ä¸€ä¸ª 256Ã—256 çš„ HHT çŸ©é˜µï¼Œä½¿ç”¨é”® `'hht'` å­˜å‚¨ã€‚

### ğŸ”§ æ¨¡å—åŠŸèƒ½

**1. `train.py` - ç”Ÿäº§è®­ç»ƒè„šæœ¬**
- ä»ç›®å½•åŠ è½½ .npz æ–‡ä»¶
- è§£ææ–‡ä»¶åæå–æ€§åˆ«å’ŒåŠ¨ä½œæ ‡ç­¾
- è®­ç»ƒ CNN ç¼–ç å™¨æå–ç‰¹å¾
- åœ¨æå–çš„ç‰¹å¾ä¸Šè®­ç»ƒ SVM åˆ†ç±»å™¨
- ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆç¼–ç å™¨ã€ç¼©æ”¾å™¨ã€SVMã€å…ƒæ•°æ®ï¼‰
- åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
- å¯¹æµ‹è¯•æ–‡ä»¶ï¼ˆä»¥ "Test" å¼€å¤´çš„æ–‡ä»¶ï¼‰è¿è¡Œæ¨ç†

**2. `inference.py` - æ¨ç†è„šæœ¬**
- ä»æ£€æŸ¥ç‚¹åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
- å¤„ç†å•ä¸ªæ–‡ä»¶æˆ–æ‰¹é‡æ–‡ä»¶
- è¾“å‡ºé¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦åˆ†æ•°
- å°†ç»“æœä¿å­˜ä¸º JSON

**3. `generate_sample_data.py` - æ•°æ®ç”Ÿæˆå™¨**
- åˆ›å»ºç”¨äºæµ‹è¯•çš„åˆæˆ 256Ã—256 HHT çŸ©é˜µ
- ç”Ÿæˆæ­£ç¡®çš„æ–‡ä»¶åæ ¼å¼
- ç”¨äºæµ‹è¯•æµç¨‹

**4. Jupyter ç¬”è®°æœ¬ `semg_hht_cnn_classifier.ipynb`**
- äº¤äº’å¼æ¢ç´¢å’Œå¯è§†åŒ–
- ä¸ Kaggle æ•°æ®é›†é›†æˆ
- åˆ†æ­¥è®­ç»ƒå·¥ä½œæµç¨‹
- é€‚åˆå®éªŒ

### ğŸ“ˆ è®­ç»ƒæµç¨‹

1. **æ•°æ®åŠ è½½**ï¼šåŠ è½½æ‰€æœ‰ .npz æ–‡ä»¶ï¼Œè¿‡æ»¤æµ‹è¯•æ–‡ä»¶ï¼ˆä»¥ "Test" å¼€å¤´ï¼‰
2. **ç‰¹å¾æå–**ï¼šCNN ç¼–ç å™¨å¤„ç† 256Ã—256 çŸ©é˜µ â†’ 256 ç»´å‘é‡
3. **å½’ä¸€åŒ–**ï¼šStandardScaler å½’ä¸€åŒ–ç‰¹å¾
4. **SVM è®­ç»ƒ**ï¼šRBF æ ¸ SVM åœ¨å½’ä¸€åŒ–ç‰¹å¾ä¸Šè®­ç»ƒ
5. **éªŒè¯**ï¼šè®¡ç®—å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1 åˆ†æ•°
6. **æµ‹è¯•æ¨ç†**ï¼šé¢„æµ‹æµ‹è¯•æ–‡ä»¶çš„æ ‡ç­¾
7. **ä¿å­˜æ£€æŸ¥ç‚¹**ï¼šä¿å­˜å®Œæ•´æ¨¡å‹çŠ¶æ€

---

## ğŸ“š Additional Resources | å…¶ä»–èµ„æº

- **Detailed Training Guide | è¯¦ç»†è®­ç»ƒæŒ‡å—**: [TRAINING_GUIDE.md](TRAINING_GUIDE.md)
- **Scripts Documentation | è„šæœ¬æ–‡æ¡£**: [SCRIPTS_README.md](SCRIPTS_README.md)
- **Example Workflow | ç¤ºä¾‹å·¥ä½œæµ**: [example_workflow.sh](example_workflow.sh)

## ğŸ“„ License | è®¸å¯è¯

MIT License - See main repository for details.
MIT è®¸å¯è¯ - è¯¦è§ä¸»ä»“åº“ã€‚

## ğŸ¤ Contributing | è´¡çŒ®

Contributions are welcome! Please maintain the CNN architecture and update documentation.
æ¬¢è¿è´¡çŒ®ï¼è¯·ä¿æŒ CNN æ¶æ„ä¸å˜å¹¶æ›´æ–°æ–‡æ¡£ã€‚
